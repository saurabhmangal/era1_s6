{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0m2JWFliFfKT"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### this is for running in local ###\n",
    "try:\n",
    "    os.environ['HTTP_PROXY']='http://185.46.212.90:80'\n",
    "    os.environ['HTTPS_PROXY']='http://185.46.212.90:80'\n",
    "    print (\"proxy_exported\")\n",
    "except:\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 4, kernel_size=3, padding=1)\n",
    "#         self.bn1 = nn.BatchNorm2d(4)\n",
    "#         self.dropout1 = nn.Dropout2d(p=0.01)\n",
    "\n",
    "#         self.conv2 = nn.Conv2d(4, 8, kernel_size=3, padding=1)\n",
    "#         self.bn2 = nn.BatchNorm2d(8)\n",
    "#         self.dropout2 = nn.Dropout2d(p=0.01)\n",
    "\n",
    "#         self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "#         self.conv3 = nn.Conv2d(8, 16, 3, padding=1)\n",
    "#         self.bn3 = nn.BatchNorm2d(16)\n",
    "#         self.dropout3 = nn.Dropout2d(p=0.01)\n",
    "\n",
    "#         self.conv4 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "#         self.bn4 = nn.BatchNorm2d(32)\n",
    "#         self.dropout4 = nn.Dropout2d(p=0.01)\n",
    "\n",
    "#         self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "#         self.avgpool = nn.AdaptiveAvgPool2d(1)  # Global Average Pooling\n",
    "\n",
    "#         self.fc = nn.Linear(32, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.dropout1(self.bn1(F.relu(self.conv1(x))))\n",
    "#         x = self.pool1(self.dropout2(self.bn2(F.relu(self.conv2(x)))))\n",
    "#         x = self.dropout3(self.bn3(F.relu(self.conv3(x))))\n",
    "#         x = self.pool2(self.dropout4(self.bn4(F.relu(self.conv4(x)))))\n",
    "\n",
    "#         x = self.avgpool(x)\n",
    "#         x = x.view(-1, 32)\n",
    "\n",
    "#         x = self.fc(x)\n",
    "#         x = F.log_softmax(x, dim=1)\n",
    "\n",
    "#         return x\n",
    "\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "# device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "# model = Net().to(device)\n",
    "# summary(model, input_size=(1, 28, 28))\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=128,\n",
    "        kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=128)\n",
    "        \n",
    "        self.tns1 = nn.Conv2d(in_channels=128, out_channels=4,\n",
    "        kernel_size=1, padding=1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=16,\n",
    "        kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=16)\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=16,\n",
    "        kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=16)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=16, out_channels=32,\n",
    "        kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=32)\n",
    "       \n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.tns2 = nn.Conv2d(in_channels=32, out_channels=16,\n",
    "        kernel_size=1, padding=1)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(in_channels=16, out_channels=16,\n",
    "        kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(num_features=16)\n",
    "        \n",
    "        self.conv6 = nn.Conv2d(in_channels=16, out_channels=32,\n",
    "        kernel_size=3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(num_features=32)\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(in_channels=32, out_channels=10,\n",
    "        kernel_size=1, padding=1)\n",
    "        self.gpool = nn.AvgPool2d(kernel_size=7)\n",
    "        self.drop = nn.Dropout2d(0.1)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.tns1(self.drop(self.bn1(F.relu(self.conv1(x)))))\n",
    "        x = self.drop(self.bn2(F.relu(self.conv2(x))))\n",
    "        x = self.pool1(x)\n",
    "        x = self.drop(self.bn3(F.relu(self.conv3(x))))\n",
    "        x = self.drop(self.bn4(F.relu(self.conv4(x))))\n",
    "        x = self.tns2(self.pool2(x))\n",
    "        x = self.drop(self.bn5(F.relu(self.conv5(x))))\n",
    "        x = self.drop(self.bn6(F.relu(self.conv6(x))))\n",
    "        x = self.conv7(x)\n",
    "        x = self.gpool(x)\n",
    "        x = x.view(-1, 10)\n",
    "        return F.log_softmax(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 128, 28, 28]           1,280\n",
      "       BatchNorm2d-2          [-1, 128, 28, 28]             256\n",
      "         Dropout2d-3          [-1, 128, 28, 28]               0\n",
      "            Conv2d-4            [-1, 4, 30, 30]             516\n",
      "            Conv2d-5           [-1, 16, 30, 30]             592\n",
      "       BatchNorm2d-6           [-1, 16, 30, 30]              32\n",
      "         Dropout2d-7           [-1, 16, 30, 30]               0\n",
      "         MaxPool2d-8           [-1, 16, 15, 15]               0\n",
      "            Conv2d-9           [-1, 16, 15, 15]           2,320\n",
      "      BatchNorm2d-10           [-1, 16, 15, 15]              32\n",
      "        Dropout2d-11           [-1, 16, 15, 15]               0\n",
      "           Conv2d-12           [-1, 32, 15, 15]           4,640\n",
      "      BatchNorm2d-13           [-1, 32, 15, 15]              64\n",
      "        Dropout2d-14           [-1, 32, 15, 15]               0\n",
      "        MaxPool2d-15             [-1, 32, 7, 7]               0\n",
      "           Conv2d-16             [-1, 16, 9, 9]             528\n",
      "           Conv2d-17             [-1, 16, 9, 9]           2,320\n",
      "      BatchNorm2d-18             [-1, 16, 9, 9]              32\n",
      "        Dropout2d-19             [-1, 16, 9, 9]               0\n",
      "           Conv2d-20             [-1, 32, 9, 9]           4,640\n",
      "      BatchNorm2d-21             [-1, 32, 9, 9]              64\n",
      "        Dropout2d-22             [-1, 32, 9, 9]               0\n",
      "           Conv2d-23           [-1, 10, 11, 11]             330\n",
      "AdaptiveAvgPool2d-24             [-1, 10, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 17,646\n",
      "Trainable params: 17,646\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.05\n",
      "Params size (MB): 0.07\n",
      "Estimated Total Size (MB): 3.12\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36407/2135698860.py:66: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 128, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.dropout1 = nn.Dropout2d(p=0.01)\n",
    "\n",
    "        self.tns_conv1 = nn.Conv2d(128, 4, kernel_size=1, padding=1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(4, 16, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.dropout2 = nn.Dropout2d(p=0.01)\n",
    "        \n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(16)\n",
    "        self.dropout3 = nn.Dropout2d(p=0.01)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(32)\n",
    "        self.dropout4 = nn.Dropout2d(p=0.01)   \n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.tns_conv2 = nn.Conv2d(32, 16, kernel_size=1, padding=1)\n",
    "    \n",
    "        \n",
    "        self.conv5 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(16)\n",
    "        self.dropout5 = nn.Dropout2d(p=0.01) \n",
    "        \n",
    "        self.conv6 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(32)\n",
    "        self.dropout6 = nn.Dropout2d(p=0.01) \n",
    "        \n",
    "        \n",
    "        self.conv7 = nn.Conv2d(32, 10, kernel_size=1, padding=1)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(self.bn1(F.relu(self.conv1(x))))\n",
    "        x = self.tns_conv1(x)\n",
    "        x = self.dropout2(self.bn2(F.relu(self.conv2(x))))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout3(self.bn3(F.relu(self.conv3(x))))\n",
    "        x = self.dropout4(self.bn4(F.relu(self.conv4(x))))\n",
    "        x = self.pool2(x)\n",
    "        x = self.tns_conv2(x)\n",
    "        x = self.dropout5(self.bn5(F.relu(self.conv5(x))))\n",
    "        x = self.dropout6(self.bn6(F.relu(self.conv6(x))))\n",
    "        x = self.conv7(x)\n",
    "        x = self.gap(x)\n",
    "        \n",
    "        x = x.view(-1, 10)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 128, 28, 28]           1,280\n",
      "       BatchNorm2d-2          [-1, 128, 28, 28]             256\n",
      "         Dropout2d-3          [-1, 128, 28, 28]               0\n",
      "            Conv2d-4            [-1, 8, 30, 30]           1,032\n",
      "            Conv2d-5           [-1, 16, 30, 30]           1,168\n",
      "       BatchNorm2d-6           [-1, 16, 30, 30]              32\n",
      "         Dropout2d-7           [-1, 16, 30, 30]               0\n",
      "         MaxPool2d-8           [-1, 16, 15, 15]               0\n",
      "            Conv2d-9           [-1, 16, 15, 15]           2,320\n",
      "      BatchNorm2d-10           [-1, 16, 15, 15]              32\n",
      "        Dropout2d-11           [-1, 16, 15, 15]               0\n",
      "           Conv2d-12           [-1, 32, 15, 15]           4,640\n",
      "      BatchNorm2d-13           [-1, 32, 15, 15]              64\n",
      "        Dropout2d-14           [-1, 32, 15, 15]               0\n",
      "        MaxPool2d-15             [-1, 32, 7, 7]               0\n",
      "           Conv2d-16             [-1, 16, 9, 9]             528\n",
      "           Conv2d-17             [-1, 16, 9, 9]           2,320\n",
      "      BatchNorm2d-18             [-1, 16, 9, 9]              32\n",
      "        Dropout2d-19             [-1, 16, 9, 9]               0\n",
      "           Conv2d-20             [-1, 32, 9, 9]           4,640\n",
      "      BatchNorm2d-21             [-1, 32, 9, 9]              64\n",
      "        Dropout2d-22             [-1, 32, 9, 9]               0\n",
      "           Conv2d-23           [-1, 10, 11, 11]             330\n",
      "AdaptiveAvgPool2d-24             [-1, 10, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 18,738\n",
      "Trainable params: 18,738\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.08\n",
      "Params size (MB): 0.07\n",
      "Estimated Total Size (MB): 3.15\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36407/3257680800.py:66: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 128, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.dropout1 = nn.Dropout2d(p=0.05)\n",
    "\n",
    "        self.tns_conv1 = nn.Conv2d(128, 8, kernel_size=1, padding=1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.dropout2 = nn.Dropout2d(p=0.05)\n",
    "        \n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(16)\n",
    "        self.dropout3 = nn.Dropout2d(p=0.05)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(32)\n",
    "        self.dropout4 = nn.Dropout2d(p=0.05)   \n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.tns_conv2 = nn.Conv2d(32, 16, kernel_size=1, padding=1)\n",
    "    \n",
    "        \n",
    "        self.conv5 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(16)\n",
    "        self.dropout5 = nn.Dropout2d(p=0.05) \n",
    "        \n",
    "        self.conv6 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(32)\n",
    "        self.dropout6 = nn.Dropout2d(p=0.05) \n",
    "        \n",
    "        \n",
    "        self.conv7 = nn.Conv2d(32, 10, kernel_size=1, padding=1)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(self.bn1(F.relu(self.conv1(x))))\n",
    "        x = self.tns_conv1(x)\n",
    "        x = self.dropout2(self.bn2(F.relu(self.conv2(x))))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout3(self.bn3(F.relu(self.conv3(x))))\n",
    "        x = self.dropout4(self.bn4(F.relu(self.conv4(x))))\n",
    "        x = self.pool2(x)\n",
    "        x = self.tns_conv2(x)\n",
    "        x = self.dropout5(self.bn5(F.relu(self.conv5(x))))\n",
    "        x = self.dropout6(self.bn6(F.relu(self.conv6(x))))\n",
    "        x = self.conv7(x)\n",
    "        x = self.gap(x)\n",
    "        \n",
    "        x = x.view(-1, 10)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DqTWLaM5GHgH"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "batch_size = 128*4\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_data, batch_label = next(iter(train_loader)) \n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(12):\n",
    "  plt.subplot(3,4,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(batch_data[i].squeeze(0), cmap='gray')\n",
    "  plt.title(batch_label[i].item())\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8fDefDhaFlwH"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader)\n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MMWbLWO6FuHb",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/118 [00:00<?, ?it/s]/tmp/ipykernel_36407/3257680800.py:66: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n",
      "loss=0.15526869893074036 batch_id=117: 100% 118/118 [00:09<00:00, 13.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1099, Accuracy: 9690/10000 (96.90%)\n",
      "\n",
      "#epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.08858007192611694 batch_id=117: 100% 118/118 [00:08<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0764, Accuracy: 9745/10000 (97.45%)\n",
      "\n",
      "#epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.09641000628471375 batch_id=117: 100% 118/118 [00:08<00:00, 13.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0496, Accuracy: 9860/10000 (98.60%)\n",
      "\n",
      "#epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.02469770796597004 batch_id=117: 100% 118/118 [00:08<00:00, 13.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0521, Accuracy: 9822/10000 (98.22%)\n",
      "\n",
      "#epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.06552869826555252 batch_id=117: 100% 118/118 [00:08<00:00, 13.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0358, Accuracy: 9882/10000 (98.82%)\n",
      "\n",
      "#epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.07001551985740662 batch_id=117: 100% 118/118 [00:08<00:00, 13.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0373, Accuracy: 9881/10000 (98.81%)\n",
      "\n",
      "#epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.04734927788376808 batch_id=117: 100% 118/118 [00:08<00:00, 13.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0355, Accuracy: 9894/10000 (98.94%)\n",
      "\n",
      "#epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.038803815841674805 batch_id=117: 100% 118/118 [00:08<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0285, Accuracy: 9910/10000 (99.10%)\n",
      "\n",
      "#epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.027869613841176033 batch_id=117: 100% 118/118 [00:08<00:00, 13.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0288, Accuracy: 9904/10000 (99.04%)\n",
      "\n",
      "#epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.008248862810432911 batch_id=117: 100% 118/118 [00:08<00:00, 13.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0281, Accuracy: 9904/10000 (99.04%)\n",
      "\n",
      "#epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.03867989405989647 batch_id=117: 100% 118/118 [00:08<00:00, 13.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0299, Accuracy: 9903/10000 (99.03%)\n",
      "\n",
      "#epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.10681498050689697 batch_id=117: 100% 118/118 [00:08<00:00, 13.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 9925/10000 (99.25%)\n",
      "\n",
      "#epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.04783479496836662 batch_id=117: 100% 118/118 [00:08<00:00, 13.59it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 9915/10000 (99.15%)\n",
      "\n",
      "#epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.012179523706436157 batch_id=117: 100% 118/118 [00:08<00:00, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 9931/10000 (99.31%)\n",
      "\n",
      "#epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.04689979553222656 batch_id=117: 100% 118/118 [00:08<00:00, 13.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 9916/10000 (99.16%)\n",
      "\n",
      "#epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.02021927759051323 batch_id=117: 100% 118/118 [00:08<00:00, 13.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 9934/10000 (99.34%)\n",
      "\n",
      "#epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.025678804144263268 batch_id=117: 100% 118/118 [00:08<00:00, 13.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 9939/10000 (99.39%)\n",
      "\n",
      "#epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.05864516273140907 batch_id=117: 100% 118/118 [00:08<00:00, 13.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 9939/10000 (99.39%)\n",
      "\n",
      "#epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.010900513269007206 batch_id=117: 100% 118/118 [00:08<00:00, 13.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 9928/10000 (99.28%)\n",
      "\n",
      "#epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.005078038666397333 batch_id=117: 100% 118/118 [00:08<00:00, 13.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 9933/10000 (99.33%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1, verbose=True)  #include to reduce learning rate\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    print (\"#epoch\", f'{epoch}')\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "    #scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "So5uk4EkHW6R"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
